{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import main libraries/packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore annoying IPython warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix, hstack # to get memory-efficient representation of matrices (sparse format)\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "# preprocessing / feature extraction / feature transformation\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# metrics/validation\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# model serialization/deserialization\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking from .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "        \n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "'''\n",
    "df = getDF('reviews_Movies_and_TV_5.json.gz')\n",
    "train, test = train_test_split(df.asin.unique(), test_size=0.1, random_state=42)\n",
    "df_train = df[df.asin.isin(train) & (df.overall != 3)].copy()\n",
    "df_test = df[df.asin.isin(test) & (df.overall != 3)].copy()\n",
    "df_train['overall'] = df_train['overall'].apply(lambda x: 1 if x > 3 else 0)\n",
    "df_test['overall'] = df_test['overall'].apply(lambda x: 1 if x > 3 else 0)\n",
    "df_train[['overall', 'reviewText', 'asin']].to_csv('csv/train.csv', index=False)\n",
    "df_test[['overall', 'reviewText']].to_csv('csv/test.csv', index=False)\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review count: 1343971\n"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "train_df_names = ['csv/train.csv']\n",
    "\n",
    "df = pd.concat((pd.read_csv(name, engine='c', sep=',', \n",
    "                 usecols=['overall', 'reviewText']) for name in train_df_names), ignore_index=True)\n",
    "\n",
    "df = df.rename(columns={'overall' : 'label', 'reviewText' : 'text'}) # rename columns\n",
    "\n",
    "# load test dataset\n",
    "df_test = pd.read_csv('csv/test.csv', sep=\",\", engine='c', usecols=['overall', 'reviewText'])\n",
    "df_test = df_test.rename(columns={'overall' : 'label', 'reviewText' : 'text'})\n",
    "\n",
    "# other test datasets\n",
    "test_RT = pd.read_csv(\"csv/reviews_rt_all.csv\", sep=\"|\", engine='c', usecols=['label', 'text'])\n",
    "test_imdb = pd.read_csv(\"csv/imdb_small.csv\", sep=\"|\", engine='c', usecols=['label', 'text'])\n",
    "test_polarity_RT = pd.read_csv(\"csv/test_reviews.csv\", sep=\"|\", engine='c', usecols=['label', 'text'])\n",
    "\n",
    "# to avoid some errors in 'object'-typed column\n",
    "df.text = df.text.apply(str)\n",
    "df_test.text = df_test.text.apply(str)\n",
    "test_RT.text = test_RT.text.apply(str)\n",
    "test_imdb.text = test_imdb.text.apply(str)\n",
    "test_polarity_RT.text = test_polarity_RT.text.apply(str)\n",
    "\n",
    "print('review count: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a charming version of the classic Dick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry Winkler is very good in this twist on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This is one of the best Scrooge movies out.  H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>This has been a favorite movie of mine for a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the American adaptation of the Charles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  This is a charming version of the classic Dick...\n",
       "1      1  Henry Winkler is very good in this twist on th...\n",
       "2      1  This is one of the best Scrooge movies out.  H...\n",
       "3      1  This has been a favorite movie of mine for a l...\n",
       "4      1  This is the American adaptation of the Charles..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance Train set: \n",
      " 1    1158561\n",
      "0     185410\n",
      "Name: label, dtype: int64\n",
      "\n",
      " class balance Test set: \n",
      " 1    131041\n",
      "0     21219\n",
      "Name: label, dtype: int64\n",
      "\n",
      " class balance Test RT set: \n",
      " 1    64658\n",
      "0    37952\n",
      "Name: label, dtype: int64\n",
      "\n",
      " class balance Test imdb set: \n",
      " 1    25000\n",
      "0    25000\n",
      "Name: label, dtype: int64\n",
      "\n",
      " class balance Test polarity RT set: \n",
      " 1    5330\n",
      "0    5330\n",
      "Name: label, dtype: int64\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# check for class balance\n",
    "print('class balance Train set:', '\\n', df.label.value_counts())\n",
    "print('\\n','class balance Test set:', '\\n', df_test.label.value_counts())\n",
    "print('\\n','class balance Test RT set:', '\\n', test_RT.label.value_counts())\n",
    "print('\\n','class balance Test imdb set:', '\\n', test_imdb.label.value_counts())\n",
    "print('\\n','class balance Test polarity RT set:', '\\n', test_polarity_RT.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance: \n",
      " 1    814590\n",
      "0    185410\n",
      "Name: label, dtype: int64\n",
      "Wall time: 307 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# imbalanced data\n",
    "#df_small = df.sample(500000, random_state=50)\n",
    "\n",
    "# balanced data\n",
    "df_small = pd.concat([df[df.label == 1].sample(814590, random_state=50),  df[df.label == 0].sample(185410, random_state=50)])\n",
    "print('class balance:', '\\n', df_small.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103191</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a great and classic movie that I basic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806026</th>\n",
       "      <td>1</td>\n",
       "      <td>Everyone loves Vince Vaughn but where are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395165</th>\n",
       "      <td>1</td>\n",
       "      <td>The live action movie may be out, but those of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000240</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a nice compilation of Olivia episodes....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143654</th>\n",
       "      <td>1</td>\n",
       "      <td>I didn't get out to see this one when it came ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "103191       1  This is a great and classic movie that I basic...\n",
       "806026       1  Everyone loves Vince Vaughn but where are the ...\n",
       "395165       1  The live action movie may be out, but those of...\n",
       "1000240      1  This is a nice compilation of Olivia episodes....\n",
       "143654       1  I didn't get out to see this one when it came ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_rate(s):\n",
    "    candidates = re.findall(r'(\\d{1,3}[\\\\|/]{1}\\d{1,2})', s)\n",
    "    rates = []\n",
    "    for c in candidates:\n",
    "        try:\n",
    "            rates.append(eval(c))\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "    return np.median(rates)\n",
    "\n",
    "# regular expression to split review on sentences\n",
    "sentence_splitter = re.compile('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\!|\\?|\\.)\\s')\n",
    "\n",
    "# lists of positive/negative smiles\n",
    "positive_smiles = set([\n",
    "\":‑)\",\":)\",\":-]\",\":]\",\":-3\",\":3\",\":->\",\":>\",\"8-)\",\"8)\",\":-}\",\":}\",\":o)\",\":c)\",\":^)\",\"=]\",\"=)\",\":‑D\",\":D\",\"8‑D\",\"8D\",\n",
    "\"x‑D\",\"xD\",\"X‑D\",\"XD\",\"=D\",\"=3\",\"B^D\",\":-))\",\";‑)\",\";)\",\"*-)\",\"*)\",\";‑]\",\";]\",\";^)\",\":‑,\",\";D\",\":‑P\",\":P\",\"X‑P\",\"XP\",\n",
    "\"x‑p\",\"xp\",\":‑p\",\":p\",\":‑Þ\",\":Þ\",\":‑þ\",\":þ\",\":‑b\",\":b\",\"d:\",\"=p\",\">:P\", \":'‑)\", \":')\",  \":-*\", \":*\", \":×\"\n",
    "])\n",
    "negative_smiles = set([\n",
    "\":‑(\",\":(\",\":‑c\",\":c\",\":‑<\",\":<\",\":‑[\",\":[\",\":-||\",\">:[\",\":{\",\":@\",\">:(\",\"D‑':\",\"D:<\",\"D:\",\"D8\",\"D;\",\"D=\",\"DX\",\":‑/\",\n",
    "\":/\",\":‑.\",'>:\\\\', \">:/\", \":\\\\\", \"=/\" ,\"=\\\\\", \":L\", \"=L\",\":S\",\":‑|\",\":|\",\"|‑O\",\"<:‑|\"\n",
    "])\n",
    "\n",
    "# pattern to catch SUCH WORDS and ignore SuCH :)\n",
    "uppercase_pattern = re.compile(r'(\\b[0-9]*[A-Z]+[0-9]*[A-Z]{1,}[0-9]*\\b)')\n",
    "\n",
    "# contrast conjugations\n",
    "contrast_conj = set([\n",
    "'alternatively','anyway','but','by contrast','differ from','elsewhere','even so','however','in contrast','in fact',\n",
    "'in other respects','in spite of','in that respect','instead','nevertheless','on the contrary','on the other hand',\n",
    "'rather','though','whereas','yet'])\n",
    "\n",
    "# to get review \"purity\" ~ same sentiment over review (~1) or not (~0)\n",
    "def purity(sentences):\n",
    "    polarities = np.array([TextBlob(x).sentiment.polarity for x in sentences])\n",
    "    return polarities.sum() / np.abs(polarities).sum()\n",
    "\n",
    "# feature engineering ^-^\n",
    "def get_custom_features(text):\n",
    "    # assume text = pd.Series with review text\n",
    "    print('extracting custom features...')\n",
    "    tdf = pd.DataFrame()\n",
    "    tdf['text'] = text \n",
    "    \n",
    "    # feature 4 - totally uppercase words (like HOLY JESUS!)\n",
    "    tdf['upper_word_cnt'] = tdf.text.apply(lambda s: len(re.findall(uppercase_pattern, s)))\n",
    "    \n",
    "    # try to extract rating :) like \"great film. 9/10\" will yield 0.9\n",
    "    tdf['rating'] = tdf['text'].apply(get_rate).fillna(-1) # feature 5 - rating (if found in review)\n",
    "\n",
    "    # try to extract smiles and count positive/negative smiles per review (features 6,7)\n",
    "    tdf['positive_smiles'] = tdf.text.apply(lambda s: len([x for x in s.split() if x in positive_smiles]))\n",
    "    tdf['negative_smiles'] = tdf.text.apply(lambda s: len([x for x in s.split() if x in negative_smiles]))\n",
    "     \n",
    "    return csr_matrix(tdf[tdf.columns[2:]].values) # to get sparse format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXTRACTOR\n",
    "extraction_list = []\n",
    "\n",
    "# 1. custom features\n",
    "extraction_list.append(['custom_features', \n",
    "                             FunctionTransformer(func=get_custom_features,\n",
    "                                                 validate=False,\n",
    "                                                 accept_sparse=True\n",
    "                                                )\n",
    "                            ])\n",
    "# 2. simple bag-of-words (tf-idf)\n",
    "extraction_list.append(['tfidf', \n",
    "                             TfidfVectorizer(decode_error='ignore',\n",
    "                                             max_df=0.75, \n",
    "                                             min_df=3,\n",
    "                                             ngram_range=(1, 3),\n",
    "                                             max_features=None,\n",
    "                                             stop_words='english'\n",
    "                                            )\n",
    "                            ])\n",
    "\n",
    "extractor = FeatureUnion(extraction_list)\n",
    "\n",
    "\n",
    "# CLASSIFIER\n",
    "clf = ExtraTreesClassifier(n_estimators=50, \n",
    "                             max_leaf_nodes=None, \n",
    "                             verbose=2,\n",
    "                             min_samples_leaf=3, \n",
    "                             random_state=1,\n",
    "                             n_jobs=-1,\n",
    "                             class_weight='balanced',\n",
    "                             criterion='entropy'\n",
    "                            )\n",
    "\n",
    "# create pipeline, combining steps together                                                                                                                       \n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', extractor),\n",
    "        ('clf', clf)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 23.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally fitted :)\n",
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation: 0.88306\n",
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    8.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.86      0.73     18541\n",
      "          1       0.96      0.89      0.93     81459\n",
      "\n",
      "avg / total       0.90      0.88      0.89    100000\n",
      "\n",
      "Wall time: 40min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   10.6s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    df_small.text, \n",
    "                                                    df_small.label, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=50, \n",
    "                                                    stratify=df_small.label\n",
    "                                                   )\n",
    "\n",
    "\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "print('finally fitted :)')\n",
    "\n",
    "#check results on validation\n",
    "print('Accuracy on validation: {}'.format(accuracy_score(model.predict(X_test), y_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   10.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.41      0.52     37952\n",
      "          1       0.72      0.91      0.81     64658\n",
      "\n",
      "avg / total       0.73      0.73      0.70    102610\n",
      "\n",
      "accuracy: 0.725163239450346\n",
      "Wall time: 21.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   14.1s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test predict RT\n",
    "X, y = test_RT.text, test_RT.label\n",
    "y_pred_RT = model.predict(X)\n",
    "print(classification_report(y, y_pred_RT))\n",
    "print('accuracy: {}'.format(accuracy_score(y, y_pred_RT)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.92      0.87     25000\n",
      "          1       0.90      0.80      0.85     25000\n",
      "\n",
      "avg / total       0.86      0.86      0.86     50000\n",
      "\n",
      "accuracy: 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "# test predict imdb\n",
    "X, y = test_imdb.text, test_imdb.label\n",
    "y_pred_imdb = model.predict(X)\n",
    "print(classification_report(y, y_pred_imdb ))\n",
    "print('accuracy: {}'.format(accuracy_score(y, y_pred_imdb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.42      0.56      5330\n",
      "          1       0.61      0.91      0.73      5330\n",
      "\n",
      "avg / total       0.72      0.66      0.64     10660\n",
      "\n",
      "accuracy: 0.6647279549718574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "# test predict polarity_RT\n",
    "X, y = test_polarity_RT.text, test_polarity_RT.label\n",
    "y_pred_pol = model.predict(X)\n",
    "print(classification_report(y, y_pred_pol))\n",
    "print('accuracy: {}'.format(accuracy_score(y, y_pred_pol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   11.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.86      0.67     21219\n",
      "          1       0.97      0.89      0.93    131041\n",
      "\n",
      "avg / total       0.92      0.88      0.89    152260\n",
      "\n",
      "accuracy: 0.8831144095625904\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:   14.9s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test predict\n",
    "X, y = df_test.text, df_test.label\n",
    "y_pred = model.predict(X)\n",
    "print(classification_report(y, y_pred)) # смотреть на значение f1-score в строке для класса 0\n",
    "print('accuracy: {}'.format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
